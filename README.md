# Data-Wrangling
Most data in the real world hardly come clean and, to bring out meaningful insights from data, the data needs to be clean. To get a data clean, some wrangling processes need  to be carried out. In this project, different wrangling processes would be carried out using Python's Libraries. The project involves querying data from different data sources, cleaning and documenting the processes, then bringing out meaningful insights from them using visualzations.
## Description:
The dataset to be wrangled, analyzed and visualized is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs.
WeRateDogsis a Twitter account that rates people's dogs with a humorous comments about the dog. These ratings usually have a denominator of 10. The numerators though are almost always greater than 10. 11/10, 12/10, 13/10, etc.
In this project, the following datasets would be worked with: 
1. Enhanced Twitter Archive: 
The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets, though not everything. The archive did contain though: each tweet's text, which was used to extract rating, dog name, and dog "stage" (i.e. doggo, floofer, pupper, and puppo) to make this Twitter archive "enhanced."(according to Udacity's instructor). Of the 5000+ tweets, tweets with ratings only have been filtered for (there were 2356).
